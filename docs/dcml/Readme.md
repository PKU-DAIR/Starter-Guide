<p align="center">
    <h1 align="center">🔥 Data-Centric&LLM方向</h1>
    <p align="center">入门指南</p>
    <p align="center">
        <a href="https://github.com/PKU-DAIR">
            <img alt="Static Badge" src="https://img.shields.io/badge/%C2%A9-PKU--DAIR-%230e529d?labelColor=%23003985">
        </a>
        <a href="https://github.com/PKU-DAIR">
            <img alt="Static Badge" src="https://img.shields.io/badge/PKU--DAIR-black?logo=github">
        </a>
    </p>
</p>

> 注:⚡为**基础必读**,💎为**基础选读**,💡为**进阶阅读**

### ML/DL 入门


### 大模型入门


<details open>
<summary>

##### ML/DL 入门（如果你现在大一/大二，并且之前没有 ML/DL 相关经历和经验，那么可以在这些资源中挑着看看。）

</summary>

> 入门神课，老师很有意思。但是注意初学者不要陷入看课怪圈，花太多时间在刷课上。跟着老师的课看到20多P，看完 Transformer 就算有了基本认识，之后的主题需要用到时再去了解即可。

- `⚡` 📔 李宏毅机器学习
- `⚡` 📔 动手学深度学习
- `⚡` 📔 通用经典论文 补充中……
- `⚡` 📔 

</details>

### 强化学习入门


<details open>
<summary>

##### 大模型入门（可以主要关注复旦、人大的教材。如果比较习惯听课也 ok）

</summary>

- `⚡` 📦 大模型理论基础
- `⚡` 📦 Stanford Transformer CS25
- `⚡` 📦 Stanford LLM Basic
- `⚡` 📦 复旦大学LLM教材
- `⚡` 📦 人民大学LLM综述

</details>

<details open>
<summary>

##### 经典强化学习

</summary>

- `⚡` 📘 深度强化学习（张志华）.pdf
- `⚡` 📘 https://wcny4qa9krto.feishu.cn/wiki/KEU1wSNwaiyWNXkeE0FcPNAUnYe#share-SH3Bd9IjHoUsV8xjcBHcqylInwd

</details>

### ML数据侧入门+选方向


<details open>
<summary>

##### RLHF

</summary>

- `⚡` 📘 复旦大学LLM教材DPO、PPO、各自的优势等等https://arxiv.org/abs/2404.18922

</details>

<details open>
<summary>

##### 数据测基础：Data-Centric ML是研究使用数据生成、选择与配比等方法实现大规模，高效以及提升模型表现的研究方向。

</summary>

- `⚡` 🗞️ 
- `⚡` 🗞️ MIT DCAI 2024
- `⚡` 🗞️ 华盛顿大学 DCAI
- `⚡` 🗞️ 
- `⚡` 🗞️ 
- `⚡` 🗞️ 

</details>

<details open>
<summary>

##### 多模态大模型数据侧：多模态大模型主要分为VideoLLM和ImageLLM。这里主要研究image, video的数据生成选择

</summary>

- `⚡` 💭 多模态大模型入门文档
- `⚡` 💭 https://arxiv.org/abs/2301.12597
- `⚡` 💭 https://arxiv.org/abs/2304.10592
- `⚡` 💭 https://arxiv.org/abs/2304.08485
- `⚡` 💭 https://arxiv.org/abs/2310.03744
- `⚡` 💭 https://arxiv.org/abs/2308.12966
- `⚡` 💭 https://arxiv.org/abs/2306.02858
- `⚡` 💭 https://arxiv.org/abs/2311.10122
- `⚡` 💭 https://arxiv.org/abs/2311.17005
- `⚡` 💭 https://arxiv.org/abs/2403.15377
- `⚡` 💭 https://arxiv.org/abs/2310.03744
- `⚡` 💭 https://arxiv.org/abs/2311.06607
- `⚡` 💭 https://arxiv.org/abs/2311.12793
- `⚡` 💭 https://arxiv.org/abs/2311.10122
- `⚡` 💭 https://arxiv.org/abs/2311.17005
- `⚡` 💭 https://arxiv.org/abs/2404.03413
- `⚡` 💭 见这些论文使用的数据，同时这三个论文的模型和数据量可以训练，其余模型训练不出来（Datasets）

</details>

<details open>
<summary>

##### Data-Centric AI4Math：大模型展现了强大的语言能力。但是数学能力仍有待加强，特别是计算能力。Data-Centric AI4Math主要是研究使用数据生成、选择、配比的方式加强模型的数学能力，探究数据对于模型数学能力的影响。

</summary>

> MathLLMs：专门为解决数学问题而设计的大语言模型 | 数学知识按照难度分为小学，初中，高中和大学。大学又有很多细分，比如数学分析，高等代数以及概率论与数理统计，最优化方法，数值分析等等目前观察到的现象是说，无论是否是Math的模型，在SFT之后高中和大学数学能力都会大幅度下降，说明数据集的构建不利于高中和大学数学能力的学习

- `⚡` 📄+🔧 入门论文：
- `⚡` 📄+🔧 https://arxiv.org/abs/2402.03300https://arxiv.org/abs/2402.06332
- `⚡` 📄+🔧 https://arxiv.org/abs/2405.12209
- `⚡` 📄+🔧 数学数据集：
- `⚡` 📄+🔧 https://arxiv.org/abs/2402.03300https://arxiv.org/abs/2402.06332

</details>

<details open>
<summary>

##### 纯语言多模态大语言模型数据侧:   1）大模型的数据生成   2）大模型的思考

</summary>

> 1）大模型的数据生成大模型的生成数据和原始训练数据分布有较大差异。想要控制生成数据的分布仍然十分困难。主要是希望能够提升生成数据的可控性

2）大模型的思考
目前以GPT-o1为首的大模型引入了基于强化学习的思考机制，但这种思考机制仍不完全明确。
另一方面，基于统计信息的大模型无法保证全部正确，因此对于这种基于统计的模型，如何Verify模型的正确性十分重要。
最后，这可能会引出生成数据的终极形态，就是自我对抗学习，自我生产数据学习，无需再收集训练数据。类似AlphaGO

- `⚡` 📄+🔧 1）大模型的数据生成调研
- `⚡` 📄+🔧 生成数据分布、可控数据生成调研
- `⚡` 📄+🔧 MAGPIE: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing
- `⚡` 📄+🔧 
- `⚡` 📄+🔧 2）大模型的思考调研
- `⚡` 📄+🔧 GPT等大模型思考

</details>

### Multimodal LLM


<details open>
<summary>

##### Data Centric工具  1）Data Centric AI数据侧工具开发 主要涉及到数据生成、配比、处理、抽取模块 也有辅助模块，比如数据的压缩，AutoML，数据标注等  2）Data Centric AI数据侧工具相关的科研 比如数据的评估模块相关的科研

</summary>

> 1）Data Centric AI数据侧开发
涉及到数据生成、配比、处理、抽取
目前数据处理需要自己编写代码，每个公司都有自己数据处理的方式，更多事“小作坊式”数据处理。
我们想要写类似Pytorch的工具来统一数据处理
2）Data Centric AI数据侧工具相关的科研
在开发数据侧工具的同时，我们也需要对于其中的许多算法进行改进，比如image-caption，video-caption的评估等等

- `⚡` 📄+🔧 1）Data Centric AI数据侧开发
- `⚡` 📄+🔧 主要关注Data Juicer，要求对于数据侧有比较详细的了解
- `⚡` 📄+🔧 2）Data Centric AI数据侧工具相关的科研
- `⚡` 📄+🔧 需要对于数据侧工具有一定的了解，阅读相关的论文
- `⚡` 📄+🔧 附录：数据评估相关论文
- `⚡` 📄+🔧 Image数据评估论文
- `⚡` 📄+🔧 CLIPScore: A Reference-free Evaluation Metric for Image Captioning
- `⚡` 📄+🔧 InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation(23.05)
- `⚡` 📄+🔧 下面两篇是follow-up的新工作
- `⚡` 📄+🔧 https://arxiv.org/pdf/2406.06004
- `⚡` 📄+🔧 leverage large multimodal model
- `⚡` 📄+🔧 https://arxiv.org/pdf/2407.18589
- `⚡` 📄+🔧 Video数据评估论文
- `⚡` 📄+🔧 EMScore
- `⚡` 📄+🔧 EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching
- `⚡` 📄+🔧 PAC-S
- `⚡` 📄+🔧 Positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation

</details>

<details open>
<summary>

##### 入门文档

</summary>

- `⚡` 📄+🔧 参考多模态大模型入门文档survey：https://arxiv.org/pdf/2306.13549

</details>

<details open>
<summary>

##### Vision-Language Model中视觉特征的提取与选择 1）主流的VLM普遍使用CLIP-ViT作为Vision Encoder，通过对比学习训练的视觉编码器无法提取细粒度的图像特征，单纯增加图像分辨率对输入窗口影响过大，因此不同VE的融合（比如DINO，SigLip等）与选择是必要的。 2）当前的高分辨率VLLM将图像编码为高分辨率的visual token，计算成本过大。如何选择特定的、问题相关的高分辨率视觉特征，设计灵活高效的注意力机制是必要的。

</summary>

> 1.不同vision encoder的视觉特征分析与组合
2.Question-aware的高分辨率视觉特征的提取与注入

- `⚡` 📄+🔧 https://brave-vlms.epfl.ch/
- `⚡` 📄+🔧 https://arxiv.org/abs/2401.06209
- `⚡` 📄+🔧 https://arxiv.org/abs/2407.20228
- `⚡` 📄+🔧 https://arxiv.org/abs/2310.08825

</details>

### Multimodal & Alignment入门+选方向


<details open>
<summary>

##### MLLM中Image，video，audio等不同模态之间的对齐范式设计 1）在当前的X-to-T多模态理解模型中，通常使用简单的模块(如mlp)作为跨模态表示的桥梁，但这些方法往往因为简单的空间映射导致不同模态的表征之间产生偏差，从而影响模型的推理和生成。 2）设计更复杂且高效的跨模态对齐机制，尤其是在不同模态间的对齐机制上进行优化是必要的。

</summary>

> 1.创新性的训练范式
2.Modality Projector / Resampler的设计（拼接后输入或llm内部注入）
3.跨模态间交互的可解释性

- `⚡` 📄+🔧 https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models?tab=readme-ov-file
- `⚡` 📄+🔧 
- `⚡` 📄+🔧 https://arxiv.org/pdf/2408.05211

</details>

<details open>
<summary>

##### llm/mllm RLHF:在强化学习和rlhf的基础上开发新的对齐范式，以及专注于XAI，可解释性alignment后和数据分布

</summary>

> 1.XPO新对齐范式系列工作
2.重新modeling对齐范式，不拘泥于rlhf
3.对齐新范式系列工作
4.基于数据分布的对齐可解释性
5.训练过程的可解释性

- `⚡` 📄+🔧 PPO,DPO,IPO,KPO,SPPO等前置工作
- `⚡` 📄+🔧 https://arxiv.org/pdf/2404.18922
- `⚡` 📄+🔧 对齐survey

</details>

<details open>
<summary>

##### Downstream alignment

</summary>

> 1.医疗任务对齐
2.AIGC对齐
3.benchmark/打榜

- `⚡` 📄+🔧 

</details>

<details open>
<summary>

##### Multimodal alignment

</summary>

> 1.模态融合算法/架构
2.多模态对齐范式

- `⚡` 📄+🔧 

</details>

<details open>
<summary>

##### llm/mllm Trustworthiness ： 让AI系统更安全，鲁棒，可信

</summary>

> 1.llm/mllm攻防技术
2.多维度alignment
3.模型训练减少
4.hallucinattion的系列工作

- `⚡` 📄+🔧 Llm safety survey：
- `⚡` 📄+🔧 Mllm safety survey：
- `⚡` 📄+🔧 mllm Trustworthiness survey：

</details>

### RAG


<details open>
<summary>

##### Diffusion model

</summary>

> 1.加入encoder的diffusion

- `⚡` 📄+🔧 

</details>

