<p align="center">
    <h1 align="center">ğŸ§¬ Graphæ–¹å‘</h1>
    <p align="center">å…¥é—¨æŒ‡å—</p>
    <p align="center">
        <a href="https://github.com/PKU-DAIR">
            <img alt="Static Badge" src="https://img.shields.io/badge/%C2%A9-PKU--DAIR-%230e529d?labelColor=%23003985">
        </a>
        <a href="https://github.com/PKU-DAIR">
            <img alt="Static Badge" src="https://img.shields.io/badge/PKU--DAIR-black?logo=github">
        </a>
    </p>
</p>

> æ³¨:âš¡ä¸º**åŸºç¡€å¿…è¯»**,ğŸ’ä¸º**åŸºç¡€é€‰è¯»**,ğŸ’¡ä¸º**è¿›é˜¶é˜…è¯»**

### GNN basics


<details open>
<summary>

##### basic introduction

</summary>

- `âš¡` ğŸ“ Stanford CS224W, https://www.youtube.com/watch?v=JAB_plj2rbA

</details>

<details open>
<summary>

##### GNN model

</summary>

- `âš¡` ğŸ“„ Semi-supervised Classification with Graph Convolutional Networks
- `âš¡` ğŸ“„ Inductive Representation Learning on Large Graphs
- `âš¡` ğŸ“„ Graph Attention Networks
- `âš¡` ğŸ“„ Simplifying Graph Convolutional Networks

</details>

<details open>
<summary>

##### GNN Principle

</summary>

- `ğŸ’` ğŸ“„ Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering
- `ğŸ’` ğŸ“„ Spectral Networks and Locally Connected Networks on Graphs
- `ğŸ’¡` ğŸ“„ The Emerging Field of Signal Processing on Graphs Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains

</details>

### Heterogeneous GNN


<details open>
<summary>

##### Library

</summary>

- `âš¡` ğŸ”§ Fast Graph Representation Learning with PyTorch Geometric, https://github.com/pyg-team/pytorch_geometric
- `âš¡` ğŸ”§ Deep Graph Library: A Graph-Centric, Highly Performant Package for Graph Neural Networks, https://github.com/dmlc/dgl

</details>

<details open>
<summary>

##### Survey

</summary>

- `âš¡` ğŸ“„ A Survey on Heterogeneous Graph Embedding: Methods, Techniques, Applications and Sources

</details>

<details open>
<summary>

##### Representation Learning

</summary>

- `âš¡` ğŸ“„ metapath2vec: Scalable Representation Learning for Heterogeneous Networks

</details>

<details open>
<summary>

##### Relation based

</summary>

- `âš¡` ğŸ“„ Relation Structure-Aware Heterogeneous Graph Neural Network
- `âš¡` ğŸ“„ SCALABLE GRAPH NEURAL NETWORKS FORHETEROGENEOUS GRAPHS

</details>

<details open>
<summary>

##### Metapath-based

</summary>

> Attention

- `âš¡` ğŸ“„ Heterogeneous Graph Attention Network
- `âš¡` ğŸ“„ Simple and Efficient Heterogeneous Graph Neural Network

</details>

### Graph condensation (Homogeneous)


<details open>
<summary>

##### Metapath-free

</summary>

> Transformer

- `âš¡` ğŸ“„ Heterogeneous Graph Transformer
- `âš¡` ğŸ“„ Are we really making much progress? Revisiting, benchmarking, and refining heterogeneous graph neural networks

</details>

<details open>
<summary>

##### Towards Accuracy

</summary>

> training-based

- `âš¡` ğŸ“„ GRAPH CONDENSATION FOR GRAPH NEURAL NET-WORKS

</details>

<details open>
<summary>

##### Towards Efficiency

</summary>

> training-based

- `âš¡` ğŸ“„ Fast Graph Condensation with Structure-based Neural Tangent Kernel

</details>

<details open>
<summary>

##### Towards Generalization

</summary>

> training-based

- `âš¡` ğŸ“„ Graph Condensation via Eigenbasis Matching

</details>

### Graph condensation (Heterogeneous)


<details open>
<summary>

##### Training-free

</summary>

- `âš¡` ğŸ“„ Graph-Skeleton: âˆ¼1% Nodes are Sufficient to Represent Billion-Scale Graph

</details>

### Graph Structure Learning


<details open>
<summary>

##### Towards Accuracy

</summary>

> training-based

- `âš¡` ğŸ“„ Heterogeneous Graph Condensation

</details>

<details open>
<summary>

##### Survey

</summary>

- `âš¡` ğŸ“„ Deep Graph Structure Learning for Robust Representations: A Survey

</details>

<details open>
<summary>

##### Benchmark

</summary>

> å­¦ä¹ å¼€æºåº“

- `âš¡` ğŸ“„+ğŸ”§ GSLB: The Graph Structure Learning Benchmark Githubï¼šhttps: //github.com/GSL-Benchmark/GSLB
- `âš¡` ğŸ“„+ğŸ”§ OpenGSL: A Comprehensive Benchmark for Graph Structure Learning GitHub:  https://github.com/OpenGSL/OpenGSL

</details>

<details open>
<summary>

##### Pre-training based

</summary>

- `ğŸ’` ğŸ“„ Towards Unsupervised Deep Graph Structure Learning

</details>

<details open>
<summary>

##### Heterogeneous Graph

</summary>

- `ğŸ’` ğŸ“„ Heterogeneous Graph Structure Learning for Graph Neural Networks

</details>

### Graph Data Augmentation


<details open>
<summary>

##### Scalable GSL

</summary>

- `ğŸ’` ğŸ“„ NodeFormer: A Scalable Graph Structure Learning Transformer for Node Classification

</details>

<details open>
<summary>

##### Survey

</summary>

- `âš¡` ğŸ“„ Graph Data Augmentation for Graph Machine Learning: A Survey
- `âš¡` ğŸ“„ Data Augmentation for Deep Graph Learning: A Survey

</details>

<details open>
<summary>

##### GDA for GCL

</summary>

- `ğŸ’` ğŸ“„ An Empirical Study of Graph Contrastive Learning

</details>

<details open>
<summary>

##### AutoML + GDA

</summary>

- `ğŸ’` ğŸ“„ Learning Graph Augmentations to Learn Graph Representations

</details>

<details open>
<summary>

##### Scalable GDA

</summary>

- `ğŸ’` ğŸ“„ Robust Optimization as Data Augmentation for Large-scale Graphs

</details>

<details open>
<summary>

##### Edge-level GDA

</summary>

- `ğŸ’` ğŸ“„ Learning to Drop: Robust Graph Neural Network via Topological Denoising

</details>

### GNN System


<details open>
<summary>

##### GDA for graph-level task

</summary>

> ICML outstanding paper

- `ğŸ’` ğŸ“„ G-Mixup: Graph Data Augmentation for Graph Classification

</details>

<details open>
<summary>

##### Survey

</summary>

- `âš¡` ğŸ“„ Parallel and Distributed Graph Neural Networks An In-Depth Concurrency Analysis

</details>

<details open>
<summary>

##### Single machine

</summary>

- `âš¡` ğŸ“„+ğŸ› ï¸ PaGraph Scaling GNN Training on Large Graphs via Computation-aware Caching
- `ğŸ’` ğŸ“„+ğŸ› ï¸ Large Graph Convolutional Network Training with GPU-oriented Data Communication Architecture

</details>

<details open>
<summary>

##### Multi machine

</summary>

- `âš¡` ğŸ“„+ğŸ› ï¸ DistDGL Distributed Graph Neural Network Training for Billion-Scale Graphs
- `ğŸ’` ğŸ“„+ğŸ› ï¸ P3 Distributed Deep Graph Learning at Scale

</details>

<details open>
<summary>

##### Out-of-core training

</summary>

- `ğŸ’` ğŸ“„+ğŸ› ï¸ Ginex SSD-enabled Billion-scale Graph Neural Network Training on a Single Machine via Provably In-memory Caching

</details>

<details open>
<summary>

##### Inference

</summary>

- `ğŸ’` ğŸ“„+ğŸ› ï¸ DGI An Easy and Efficient Framework for GNN Model Evaluation

</details>

### GNN+LLM


<details open>
<summary>

##### Compiler

</summary>

- `ğŸ’` ğŸ“„+ğŸ› ï¸ Graphiler Optimizing Graph Neural Networks with Message Passing Data Flow Graph

</details>

<details open>
<summary>

##### Survey

</summary>

- `âš¡` ğŸ“„ Large Language Models on Graphs A Comprehensive Survey

</details>

<details open>
<summary>

##### GNN-centric

</summary>

- `âš¡` ğŸ“„ Harnessing Explanations LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning
- `âš¡` ğŸ“„ Empowering Text-Attributed Graph Learning with Large Language Models (LLMs)
- `âš¡` ğŸ“„ One For All Towards Training One Graph Model for All Classification Tasks

</details>

### GNN æ•°æ®æ ‡æ³¨


<details open>
<summary>

##### LLM-centric

</summary>

- `âš¡` ğŸ“„ GPT4Graph Can Large Language Models Understand Graph Structured Data An Empirical Evaluation and Benchmarking
- `âš¡` ğŸ“„ Language is All a Graph Needs
- `âš¡` ğŸ“„ GraphGPT Graph Instruction Tuning for Large Language Models
- `ğŸ’` ğŸ“„ LLaGA Lage Language and Graph Assistant

</details>

<details open>
<summary>

##### Graph active learning

</summary>

- `âš¡` ğŸ“„ Active Learning for Graph Embedding
- `âš¡` ğŸ“„ Grain Improving Data Efficiency of Graph Neural Networks via Diversified Influence Maximization
- `âš¡` ğŸ“„ ALG Fast and Accurate Active Learning Framework for Graph Convolutional Networks

</details>

<details open>
<summary>

##### Noise-aware

</summary>

- `ğŸ’` ğŸ“„ RIM Reliable Influence-based Active Learning on Graphs

</details>

### Scalable GNN (GNN Acceleration)


<details open>
<summary>

##### LLM as oracle

</summary>

- `âš¡` ğŸ“„ Label-free Node Classification on Graphs with Large Language Models (LLMs)

</details>

<details open>
<summary>

##### Training Acceleration

</summary>

- `âš¡` ğŸ“„ Inductive Representation Learning on Large Graphs
- `âš¡` ğŸ“„ FASTGCN: FAST LEARNING WITH GRAPH CONVOLU-TIONAL NETWORKS VIA IMPORTANCE SAMPLING
- `âš¡` ğŸ“„ GraphSAINT: GRAPH SAMPLING BASED INDUCTIVELEARNING METHOD
- `âš¡` ğŸ“„ Simplifying Graph Convolutional Networks
- `âš¡` ğŸ“„ Graph Attention Multi-Layer Perceptron
- `ğŸ’` ğŸ“„ PREDICT THEN PROPAGATE: GRAPH NEURALNETWORKS MEET PERSONALIZED PAGERANK

</details>

<details open>
<summary>

##### Inference Acceleration

</summary>

- `âš¡` ğŸ“„ Distilling Knowledge from Graph Convolutional Networks
- `ğŸ’` ğŸ“„ GRAPH-LESS NEURAL NETWORKS: TEACHING OLDMLPS NEW TRICKS VIA DISTILLATION
- `ğŸ’` ğŸ“„ NOSMOG: Learning Noise-robust and Structure-aware MLPs on Graphs
- `âš¡` ğŸ“„ DEGREE-QUANT: QUANTIZATION-AWARE TRAINING FOR GRAPH NEURAL NETWORKS
- `ğŸ’` ğŸ“„ THE LOTTERY TICKET HYPOTHESIS: FINDING SPARSE, TRAINABLE NEURAL NETWORKS

</details>

